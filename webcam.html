<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Livecoding GLB Scene</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #111;
        }

        canvas {
            display: block;
        }
    </style>
</head>

<body>
    <video id="webcamVideo" style="display:none;" autoplay playsinline></video>
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.167.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.167.0/examples/jsm/"
            }
        }
    </script>

    <script type="module">
        navigator.mediaDevices.getUserMedia({ video: true, audio: true })
            .then(stream => {
                video.srcObject = stream;
                video.play();
                // Call the audio setup function with the stream
                setupAudio(stream);
            })
            .catch(err => {
                console.error("Error accessing the webcam or microphone: ", err);
            });
        // Add these variables at the top of your script, right after the three.js imports
        let audioContext, analyser, dataArray = new Uint8Array(256); // Initialize with a buffer size
        // Function to set up the audio processing
        function setupAudio(stream) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            const source = audioContext.createMediaStreamSource(stream);

            // Connect the nodes
            source.connect(analyser);

            // Set up the analyser for frequency data
            analyser.fftSize = 32; // Smaller size for faster analysis
            const bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);
        }
        // Import essential three.js components
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
        // Add this to your script, replacing the textureLoader setup
        const video = document.getElementById("webcamVideo");

        // Get access to the webcam
        navigator.mediaDevices.getUserMedia({ video: true, audio: false })
            .then(stream => {
                video.srcObject = stream;
                video.play();
            })
            .catch(err => {
                console.error("Error accessing the webcam: ", err);
            });

        // Create a video texture from the webcam feed
        const videoTexture = new THREE.VideoTexture(video);
        videoTexture.colorSpace = THREE.SRGBColorSpace;
        // Define the vertex shader
        const vertexShader = `
    varying vec2 vUv;
    void main() {
        vUv = uv;
        gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
    }
`;

        // Define the fragment shader with the saturation filter
        const fragmentShader = `
    uniform sampler2D webcamTexture;
    uniform float saturation;
    varying vec2 vUv;
    
    void main() {
        vec4 color = texture2D(webcamTexture, vUv);
        
        // Simple saturation filter
        float luma = dot(color.rgb, vec3(0.299, 0.587, 0.114));
        vec3 greyscale = vec3(luma);
        vec3 saturatedColor = mix(greyscale, color.rgb, saturation);
        
        gl_FragColor = vec4(saturatedColor, color.a);
    }
`;

        // Create the shader material
        const customShaderMaterial = new THREE.ShaderMaterial({
            uniforms: {
                webcamTexture: { value: videoTexture },
                saturation: { value: 1.5 } // Set saturation level (1.0 is normal, >1.0 is more saturated)
            },
            vertexShader: vertexShader,
            fragmentShader: fragmentShader
        });

        // --- 1. Scene Setup ---
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 1, 1000);
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // Add lighting
        const ambientLight = new THREE.AmbientLight(0x404040, 2);
        scene.add(ambientLight);
        const directionalLight = new THREE.DirectionalLight(0xffffff, 1.5);
        directionalLight.position.set(5, 10, 5);
        directionalLight.castShadow = true;
        scene.add(directionalLight);

        // Optional: Add camera controls for debugging
        // const controls = new OrbitControls(camera, renderer.domElement);
        // controls.enableDamping = true;
        // --- 2. Load and Store Your Models ---
        const loader = new GLTFLoader();
        const allPaths = [];
        const currentModels = [];
        const displayGroupSize = 25; // Change this to 1 for showing one model at a time
        let modelIndex = 0;
        let lastUpdateTime = 0;
        const slideInterval = 30000; // 5 seconds between slides

        // A function to load and position models for the current window
        function loadNextGroup() {
            // Clear the scene of old models
            currentModels.forEach(model => scene.remove(model));
            currentModels.length = 0;

            for (let i = 0; i < displayGroupSize; i++) {
                const pathIndex = (modelIndex + i) % allPaths.length;
                const path = allPaths[pathIndex];

                // Position models in a line for the sliding effect
                //    const position = new THREE.Vector3((i - (displayGroupSize - 1) / 2) * 5, 0, 0);
                const x = (Math.random() - 0.5) * 5;
                const y = (Math.random() - 0.5) * 5;
                const z = (Math.random() - 0.5) * 5;
                const position = new THREE.Vector3(x, y, z);
                loader.load(path, (gltf) => {
                    const model = gltf.scene;
                    model.position.copy(position);

                    // Apply a material to avoid black meshes
                    model.traverse((child) => {
                        if (child.isMesh) {
                            //   child.material = new THREE.MeshStandardMaterial({ color: Math.random() * 0xffffff });
                            child.material = customShaderMaterial; // Apply the new shader material  
                            child.castShadow = true;
                            child.receiveShadow = true;
                        }
                    });

                    scene.add(model);
                    currentModels.push(model);
                });
            }

            modelIndex = (modelIndex + displayGroupSize) % allPaths.length;
        }

        // --- 3. Animation and Manipulation Loop ---
        function animate(time) {
            requestAnimationFrame(animate);

            // If the audio context is ready, get the frequency data
            // This copies the current frequency data into the dataArray
            analyser.getByteFrequencyData(dataArray);

            // Find the average frequency level
            let sum = 0;
            for (let i = 0; i < dataArray.length; i++) {
                sum += dataArray[i];
            }
            const average = sum / dataArray.length;

            // Map the average level to a scale factor. Use a non-linear
            // mapping for a more subtle effect.
            // The Math.log function helps make the response less jumpy
            // and more natural for voice or music.
            const scaleFactor = 1 + (average / 100);

            // Check if it's time to load the next group
            if (time - lastUpdateTime > slideInterval && allPaths.length > 0) {
                loadNextGroup();
                lastUpdateTime = time;
            }


            // Animate the camera orbit
            const orbitSpeed = 0.001; // Slower orbit speed
            const orbitRadius = 1;
            camera.position.x = Math.sin(time * orbitSpeed) * orbitRadius;
            camera.position.y = Math.sin(time * orbitSpeed) * orbitRadius;
            camera.position.z = Math.cos(time * orbitSpeed) * orbitRadius;
            camera.lookAt(0, 0, 0);

            // Rotate the models
            currentModels.forEach(model => {
                model.rotation.y += 0.001; model.rotation.x += 0.001; model.rotation.z += 0.001;

                model.scale.set(scaleFactor, scaleFactor, scaleFactor);
            });

            renderer.render(scene, camera);
        }

        // Start by fetching the paths and initializing the first group
        fetch('glbs.txt')
            .then(response => response.text())
            .then(text => {
                const paths = text.split('\n').filter(path => path.trim() !== '');
                allPaths.push(...paths);
                loadNextGroup(); // Load the first group immediately
                animate(0);
            })
            .catch(error => console.error('Error fetching glbs.txt:', error));
        animate();

        // --- 4. Handle Window Resize ---
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });
    </script>
</body>

</html>